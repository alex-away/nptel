## robustness
- a model's ability to maintain its performance and reliability even when faced with unexpected or difficult conditions.
- a robust model should generalize well and handle things like noisy data, distribution shifts, and adversarial attacks.

## black swans & long tails
- **black swans**
    - highly improbable, outlier events that have an extreme impact and are unpredictable.
    - they are a type of **unknown unknown** (risks we are not even aware of).
    - examples: the 2008 financial crisis, the covid-19 pandemic.
- **long tail distributions**
    - distributions where a few high-frequency events make up the "head," and a large number of low-frequency, rare events make up the "long tail." (pareto / 80-20 principle).
    - they are often generated by **multiplicative, nonlinear interactions** (e.g., startup success = idea * team * timing * funding). an additive process (idea + team + timing) would result in a normal distribution.

## distribution shifts
- this occurs when the data distribution a model sees during testing (or in the real world) is different from the data it was trained on.
- formally: **p_train(x,y) != p_test(x,y)**
- **types of shifts**
    - **covariate shift**: the input distribution p(x) changes, but the relationship between inputs and outputs, p(y|x), stays the same.
        - example: a self-driving car trained on sunny roads (**p_train(x)**) is then deployed in the snow (**p_test(x)**). the physics of driving (**p(y|x)**) hasn't changed, but the inputs are totally different.
    - **concept shift**: the input distribution p(x) is the same, but the relationship p(y|x) changes. the meaning of the data changes over time.
        - example: a model predicts user purchases based on Browse history. pre-pandemic, watching travel videos (**x**) predicted buying plane tickets (**y**). during the pandemic, the same Browse history predicted buying subscriptions to nature documentaries. the input is the same, but the concept has shifted.
    - **prior probability shift**: the output distribution p(y) changes, but the conditional distribution p(x|y) is constant.
        - example: a medical diagnostic model is trained on general hospital data. when deployed during flu season, the probability of the diagnosis being "flu" (**p(y)**) is much higher, even though the symptoms for the flu (**p(x|y)**) remain the same.
- **improving robustness**
    - **use larger models**: larger models often have better generalization capabilities.
    - **data augmentation**: creating modified versions of the training data to expose the model to more variations.
        - **mixup**: creates new data by taking a weighted average of two different images and their labels.
        - **augmix & pixmix**: more advanced techniques that create diverse and recognizable augmented images.